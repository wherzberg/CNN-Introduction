{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Smiley Classifier",
      "provenance": [],
      "authorship_tag": "ABX9TyNZr9UUlQtDa+9zSRUcURMC",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/wherzberg/CNN-Introduction/blob/main/Smiley_Classifier.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FICsuuQhrfOP"
      },
      "source": [
        "# Smiley Image Classifier\n",
        " - Created by Billy Herzberg\n",
        " - william.herzberg@marquette.edu\n",
        "\n",
        "This notebook will generate simulated images that do or do not have smiley faces and use a convolutional neural network to classify them.  "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LFKRJu0VvBW3"
      },
      "source": [
        "# Import Libraries and Define Functions"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rIb49CD42YyC"
      },
      "source": [
        "import tensorflow as tf\n",
        "print(\"Using Tensorflow version\",tf.__version__)\n",
        "\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib        as mpl                 # There are a few other things needed from matplotlib\n",
        "\n",
        "# Also set some things for plotting\n",
        "plt.style.use('seaborn-whitegrid')\n",
        "plt.rcParams[\"axes.grid\"] = False"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v-VrJKjg1AMB"
      },
      "source": [
        "def genData(N,n,m,p,A,B):\n",
        "    # This function will generate a data set of blurry smiley face images\n",
        "    # Inputs:\n",
        "    # -> N = Number of samples\n",
        "    # -> n = height of the images\n",
        "    # -> m = width of the images\n",
        "    # -> p = probability of a smiley face\n",
        "    # -> A = magnitude of the smiley feature\n",
        "    # -> B = standard deviation of the blurry noise\n",
        "    # Outputs:\n",
        "    # -> data = dictionary with X and Y\n",
        "    #       X = a [N,n,m,1] array of image samples\n",
        "    #       Y = a [N] array of image classifiers (1 for smiley 0 for nothing)\n",
        "\n",
        "    # Start by building the blurry backgrounds for X and a vector of 0's for Y\n",
        "    X = np.random.normal(loc=0,scale=B,size=[N,n,m,1])\n",
        "    Y = np.zeros(shape=[N])\n",
        "\n",
        "    # Then loop through each sample and maybe put a smiley\n",
        "    for k in range(N):\n",
        "\n",
        "        r = np.random.uniform()\n",
        "        if r < p: # We need to add a smiley\n",
        "            \n",
        "            # Find the top left corner of the smiley\n",
        "            row = np.random.randint(low=1,high=(n-3))\n",
        "            col = np.random.randint(low=1,high=(m-3))\n",
        "\n",
        "            # Then increase the values at the eyes and mouth\n",
        "            X[k,row  ,col  ,0] += A\n",
        "            X[k,row  ,col+2,0] += A\n",
        "            X[k,row+2,col  ,0] += A\n",
        "            X[k,row+2,col+1,0] += A\n",
        "            X[k,row+2,col+2,0] += A\n",
        "\n",
        "            # Also place a 1 in the Y vector\n",
        "            Y[k] = 1\n",
        "\n",
        "    # Now prepare the output as a dictionary and return\n",
        "    data = {\n",
        "        'X': X,\n",
        "        'Y': Y\n",
        "    }\n",
        "    return data\n",
        "\n",
        "print(\"genData is defined\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uYic7jjx3L-C"
      },
      "source": [
        "def displaySample(X,Y,k,A,B):\n",
        "    # This function will display one sample image with a title of either smiley \n",
        "    # or no smiley.\n",
        "    # Inputs:\n",
        "    # -> X = a [N,n,m] array of image samples\n",
        "    # -> Y = a [N] array of image classifiers (1 for smiley 0 for nothing)\n",
        "    # -> k = the sample number to display\n",
        "\n",
        "    # Pick out the sample\n",
        "    x = X[k,:,:].squeeze()\n",
        "\n",
        "    # Decide on a title\n",
        "    if Y[k] == 1:\n",
        "        t = \"Sample \" + str(k) + \": Smiley\"\n",
        "    else:\n",
        "        t = \"Sample \" + str(k) + \": No Smiley\"\n",
        "    \n",
        "    #\n",
        "    # Set the norm and colormap\n",
        "    norm = mpl.colors.Normalize(vmin=-3*B, vmax=3*B+A)\n",
        "    cmap='cool'\n",
        "\n",
        "    # Display the image\n",
        "    plt.imshow(x, norm=norm, cmap=cmap)\n",
        "    plt.title(t)\n",
        "    plt.axis('off')\n",
        "    plt.colorbar( plt.cm.ScalarMappable(norm=norm, cmap=cmap) )\n",
        "    plt.show()\n",
        "\n",
        "print(\"displaySample is defined\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YifduCzYoyNS"
      },
      "source": [
        "def displayIntermediateOutput(model,layer,X,Y,k):\n",
        "    # This function will display output from a layer in the model for sample k \n",
        "    # from set X.\n",
        "    # Inputs:\n",
        "    # -> model = the model to take intermediate output from\n",
        "    # -> layer = the layer number to take output from\n",
        "    # ->     X = data size [N,n,m,1] that can be fed into the network\n",
        "    # ->     Y = data size [N] that has 1 if there is a smiley, else 0\n",
        "    # ->     k = index of the data sample to be plotted\n",
        "\n",
        "    # Pick out the sample, keeping dimensions\n",
        "    x = X[k,:,:,:].reshape(1,X.shape[1],X.shape[2],1)\n",
        "    y = Y[k]\n",
        "\n",
        "    # snip the model so the output is at the desired layer\n",
        "    model_snip = tf.keras.Model( inputs=model.input, outputs=model.layers[layer].output )\n",
        "\n",
        "    # Send the sample through both models\n",
        "    #ypred1 = model.predict(x).squeeze()  # This works but gives a warning so below is used instead. I don't get it\n",
        "    #ypred2 = model_snip.predict(x).squeeze()  # This works but gives a warning so below is used instead. I don't get it\n",
        "    ypred1 = np.array(model.predict_step(x)).squeeze()\n",
        "    ypred2 = np.array(model_snip.predict_step(x)).squeeze()\n",
        "\n",
        "    # Make the title\n",
        "    if y == 1:\n",
        "        t = \"Sample \" + str(k) + \": Smiley, YPred=\"    + str(ypred1)\n",
        "    else:\n",
        "        t = \"Sample \" + str(k) + \": No Smiley, YPred=\" + str(ypred1)\n",
        "    \n",
        "    # Set the norm and colormap\n",
        "    norm = mpl.colors.Normalize(vmin=0, vmax=1)\n",
        "    cmap='cool'\n",
        "\n",
        "    # Display the image\n",
        "    plt.imshow(ypred2, norm=norm, cmap=cmap)\n",
        "    plt.title(t)\n",
        "    plt.axis('off')\n",
        "    plt.colorbar( plt.cm.ScalarMappable(norm=norm, cmap=cmap) )\n",
        "    plt.show()\n",
        "\n",
        "print(\"displayIntermediateOutput is defined\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qq8i1AAq3iHn"
      },
      "source": [
        "def displayFilterChannel(model,layer,index1,index2):\n",
        "    # Display a filter from a convolutional layer\n",
        "    # Inputs:\n",
        "    # -> model  = the model to take intermediate output from\n",
        "    # -> layer  = the layer number to take output from\n",
        "    # -> index1 = the filter channel (what channel of the input)\n",
        "    # -> index2 = the filter index (which filter to look at)\n",
        "\n",
        "    # Get the weights from the layer\n",
        "    W = model.layers[layer].get_weights()[0]\n",
        "\n",
        "    # Get the specific filter channel\n",
        "    w = W[:,:,index1,index2].squeeze()\n",
        "\n",
        "    # Make a title\n",
        "    t = \"Kernel Values\"\n",
        "\n",
        "    # Display the image\n",
        "    plt.imshow(w)\n",
        "    plt.title(t)\n",
        "    plt.axis('off')\n",
        "    plt.colorbar()\n",
        "    plt.show()\n",
        "\n",
        "print(\"displayFilterChannel is defined\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0duqBdyzqbik"
      },
      "source": [
        "# Simulate a Data Set"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DkAk2NgmyDKO"
      },
      "source": [
        "# Make a data set\n",
        "N = 100    # Number of samples\n",
        "n = 10     # Height\n",
        "m = 10     # Width\n",
        "p = 0.5    # Probability of a smiley\n",
        "A = 5      # Intensity of smiley\n",
        "B = 1      # Standard deviation of normal noise\n",
        "data = genData(N,n,m,p,A,B)\n",
        "X = data['X']    # Input images\n",
        "Y = data['Y']    # Truths\n",
        "\n",
        "# Display shapes\n",
        "print(\"The shape of X:\", data['X'].shape)\n",
        "print(\"The shape of Y:\", data['Y'].shape)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vuJhORklUBBe"
      },
      "source": [
        "for k in [0,1,2,3]:\n",
        "    displaySample(X,Y,k,A,B)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TBBeb0ZOySJ9"
      },
      "source": [
        "# Split into training and testing\n",
        "train_size = 80\n",
        "Xtrain = X[           :train_size, :, :, : ]\n",
        "Xtest  = X[ train_size:          , :, :, : ]\n",
        "Ytrain = Y[           :train_size ]\n",
        "Ytest  = Y[ train_size:           ]\n",
        "\n",
        "# Display shapes\n",
        "print(\"The shape of Xtrain:\", Xtrain.shape)\n",
        "print(\"The shape of Xtest: \",  Xtest.shape)\n",
        "print(\"The shape of Ytrain:\", Ytrain.shape)\n",
        "print(\"The shape of Ytest: \",  Ytest.shape)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tb7jESW4r8Kj"
      },
      "source": [
        "# Build a CNN Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0p9i0JRT2pD5"
      },
      "source": [
        "# Input Layer\n",
        "X0 = tf.keras.Input( shape=( n,m,1 ) )\n",
        "\n",
        "# Convolutional Layer\n",
        "C1 = tf.keras.layers.Conv2D(\n",
        "    filters     = 1,\n",
        "    kernel_size = (5,5),\n",
        "    strides     = (1,1),\n",
        "    padding     = 'same',\n",
        "    activation  = 'sigmoid'  # Sigmoid is usually the final activation function for classification\n",
        ")(X0)\n",
        "\n",
        "# Max Pool Layer\n",
        "P1 = tf.keras.layers.MaxPool2D(\n",
        "    pool_size    = (n,m)\n",
        ")(C1)\n",
        "\n",
        "# Flatten Layer\n",
        "X99 = tf.keras.layers.Flatten()(P1)\n",
        "\n",
        "# Put it all together\n",
        "model = tf.keras.Model(inputs=X0, outputs=X99)\n",
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "__vuq3hOCCQw"
      },
      "source": [
        "# Compile\n",
        "model.compile(\n",
        "    optimizer = tf.keras.optimizers.SGD( learning_rate=0.01 ), # Gradient descent\n",
        "    loss      = tf.keras.losses.BinaryCrossentropy(),\n",
        "    metrics   = ['accuracy']\n",
        ")\n",
        "print(\"Model Compiled\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2YbSpclOUT5u"
      },
      "source": [
        "# Display an image of the kernel\n",
        "l = 1\n",
        "ind1 = 0  # channel index\n",
        "ind2 = 0  # filter number\n",
        "displayFilterChannel(model,l,ind1,ind2)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OOW913_RUaQ6"
      },
      "source": [
        "# Look at intermediate output\n",
        "l = 1  # This is the convolutional layer\n",
        "for k in [0,1,2,3]:\n",
        "    displaySample(Xtest,Ytest,k,A,B)\n",
        "    displayIntermediateOutput(model,l,Xtest,Ytest,k)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bKOrMyJUUXGS"
      },
      "source": [
        "# Predict\n",
        "YtestPred = np.array(model.predict_step(Xtest)).squeeze()\n",
        "print(\"Untrained Predictions\")\n",
        "print(\"   Sample      Truth       Prediction\")\n",
        "print(\"  ------------------------------------\")\n",
        "print(np.transpose(np.array([np.arange(N-train_size),Ytest,YtestPred])))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LpJXkuFwsOL7"
      },
      "source": [
        "# Train the Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NwnEBwhwELEH"
      },
      "source": [
        "hist = model.fit(\n",
        "    x = Xtrain,\n",
        "    y = Ytrain,\n",
        "    validation_data = (Xtest, Ytest),\n",
        "    batch_size = 5,\n",
        "    epochs = 50\n",
        ")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wplPfxt7sZCQ"
      },
      "source": [
        "# Evaluate the Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n-urksL8WrUj"
      },
      "source": [
        "# Display an image of the kernel\n",
        "l = 1\n",
        "ind1 = 0  # channel index\n",
        "ind2 = 0  # filter number\n",
        "displayFilterChannel(model,l,ind1,ind2)    # -> model.get_weights()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_-6_gG4oWsCo"
      },
      "source": [
        "# Look at intermediate output\n",
        "l = 1  # This is the convolutional layer\n",
        "for k in [3,4,5,6]:\n",
        "    displaySample(Xtest,Ytest,k,A,B)\n",
        "    displayIntermediateOutput(model,l,Xtest,Ytest,k)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "01uymbUmsSvg"
      },
      "source": [
        "YtestPred = np.array(model.predict_step(Xtest)).squeeze()\n",
        "print(\"Trained Predictions\")\n",
        "print(\"   Sample      Truth       Prediction\")\n",
        "print(\"  ------------------------------------\")\n",
        "print(np.transpose(np.array([np.arange(N-train_size),Ytest,YtestPred])))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Qo7g6jEXvMTv"
      },
      "source": [
        "# Build a Bigger CNN Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w50XDcZXZI1n"
      },
      "source": [
        "# Build a bigger CNN\n",
        "X0 = tf.keras.Input( shape=( n,m,1 ) )\n",
        "\n",
        "# Convolution\n",
        "C1 = tf.keras.layers.Conv2D(\n",
        "    filters     = 30,\n",
        "    kernel_size = (3,3),\n",
        "    strides     = (1,1),\n",
        "    padding     = 'same',\n",
        "    activation  = 'relu'  \n",
        ")(X0)\n",
        "\n",
        "# Convolution\n",
        "C2 = tf.keras.layers.Conv2D(\n",
        "    filters     = 30,\n",
        "    kernel_size = (3,3),\n",
        "    strides     = (1,1),\n",
        "    padding     = 'same',\n",
        "    activation  = 'relu'  \n",
        ")(C1)\n",
        "\n",
        "# Pool\n",
        "P1 = tf.keras.layers.MaxPool2D(\n",
        "    pool_size    = (2,2),\n",
        "    strides      = (2,2)\n",
        ")(C2)\n",
        "\n",
        "# Convolution\n",
        "C3 = tf.keras.layers.Conv2D(\n",
        "    filters     = 30,\n",
        "    kernel_size = (3,3),\n",
        "    strides     = (1,1),\n",
        "    padding     = 'same',\n",
        "    activation  = 'relu'  \n",
        ")(P1)\n",
        "\n",
        "# Convolution\n",
        "C4 = tf.keras.layers.Conv2D(\n",
        "    filters     = 1,\n",
        "    kernel_size = (3,3),\n",
        "    strides     = (1,1),\n",
        "    padding     = 'same',\n",
        "    activation  = 'sigmoid'  # Sigmoid is usually the final activation function for classification\n",
        ")(C3)\n",
        "\n",
        "# Pool\n",
        "P2 = tf.keras.layers.MaxPool2D(\n",
        "    pool_size    = (5,5)\n",
        ")(C4)\n",
        "\n",
        "X99 = tf.keras.layers.Flatten()(P2)\n",
        "\n",
        "model2 = tf.keras.Model(inputs=X0, outputs=X99)\n",
        "model2.summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F3NnuF0Rae3R"
      },
      "source": [
        "# Compile\n",
        "model2.compile(\n",
        "    optimizer = tf.keras.optimizers.Adam(learning_rate=0.01),\n",
        "    loss      = tf.keras.losses.BinaryCrossentropy(),\n",
        "    metrics   = ['accuracy']\n",
        ")\n",
        "print(\"Model Compiled\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ik4fT_y-afjW"
      },
      "source": [
        "hist = model2.fit(\n",
        "    x = Xtrain,\n",
        "    y = Ytrain,\n",
        "    validation_data = (Xtest, Ytest),\n",
        "    batch_size = 5,\n",
        "    epochs = 50\n",
        ")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z7d_FSVJafri"
      },
      "source": [
        "# Display an image of the kernel\n",
        "l = 2\n",
        "ind1 = 0  # channel index\n",
        "ind2 = 0  # filter number\n",
        "for ind2 in [0,1,2,3,4,5]:\n",
        "    displayFilterChannel(model2,l,ind1,ind2)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c1trSiU0dfke"
      },
      "source": [
        "YtestPred = np.array(model2.predict_step(Xtest)).squeeze()\n",
        "print(\"Trained Predictions\")\n",
        "print(\"   Sample      Truth       Prediction\")\n",
        "print(\"  ------------------------------------\")\n",
        "print(np.transpose(np.array([np.arange(N-train_size),Ytest,YtestPred])))"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}