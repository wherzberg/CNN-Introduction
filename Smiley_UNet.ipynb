{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Smiley UNet",
      "provenance": [],
      "authorship_tag": "ABX9TyO9Y6TB8MkaDFttFL6sxYSE",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/wherzberg/CNN-Introduction/blob/main/Smiley_UNet.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w3xqQfce0kms"
      },
      "source": [
        "# Smiley Image U-Net\n",
        " - Created by Billy Herzberg\n",
        " - william.herzberg@marquette.edu\n",
        "\n",
        "This notebook will generate simulated images that have an input and a truth. If the input has a smiley face, the output will have a ring in the same location. The input has noise while the output does not."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6-mCp0j404QN"
      },
      "source": [
        "# Import Libraries and Define Functions"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cQmWyChqJevs"
      },
      "source": [
        "import tensorflow as tf\n",
        "print(\"Using Tensorflow version\",tf.__version__)\n",
        "\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib        as mpl                 # There are a few other things needed from matplotlib\n",
        "\n",
        "# Also set some things for plotting\n",
        "plt.style.use('seaborn-whitegrid')\n",
        "plt.rcParams[\"axes.grid\"] = False"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jKyrFi_zJqUS"
      },
      "source": [
        "def genData(N,n,m,p,A,B):\n",
        "    # This function will generate a data set of blurry smiley face images\n",
        "    # Inputs:\n",
        "    # -> N = Number of samples\n",
        "    # -> n = height of the images\n",
        "    # -> m = width of the images\n",
        "    # -> p = probability of a smiley face\n",
        "    # -> A = magnitude of the smiley feature\n",
        "    # -> B = standard deviation of the blurry noise\n",
        "    # Outputs:\n",
        "    # -> data = dictionary with X and Y\n",
        "    #       X = a [N,n,m,1] array of input image samples\n",
        "    #       Y = a [N,n,m,1] array of truth image samples\n",
        "\n",
        "    # Start by building the blurry backgrounds for X and a vector of 0's for Y\n",
        "    X = np.random.normal(loc=0,scale=B,size=[N,n,m,1])\n",
        "    Y = np.ones(shape=[N,n,m,1])*0.9\n",
        "\n",
        "    # Then loop through each sample and maybe put a smiley\n",
        "    for k in range(N):\n",
        "\n",
        "        r = np.random.uniform()\n",
        "        if r < p: # We need to add a smiley\n",
        "            \n",
        "            # Find the top left corner of the smiley\n",
        "            row = np.random.randint(low=1,high=(n-3))\n",
        "            col = np.random.randint(low=1,high=(m-3))\n",
        "\n",
        "            # Then increase the values at the eyes and mouth\n",
        "            X[k,row  ,col  ,0] += A\n",
        "            X[k,row  ,col+2,0] += A\n",
        "            X[k,row+2,col  ,0] += A\n",
        "            X[k,row+2,col+1,0] += A\n",
        "            X[k,row+2,col+2,0] += A\n",
        "\n",
        "            # Also if a smiley was placed, put a ring in the output\n",
        "            val = 0.5\n",
        "            Y[k,row  ,col  ,0] = val\n",
        "            Y[k,row  ,col+1,0] = val\n",
        "            Y[k,row  ,col+2,0] = val\n",
        "            Y[k,row+1,col  ,0] = val\n",
        "            Y[k,row+1,col+2,0] = val\n",
        "            Y[k,row+2,col  ,0] = val\n",
        "            Y[k,row+2,col+1,0] = val\n",
        "            Y[k,row+2,col+2,0] = val\n",
        "\n",
        "    # Now prepare the output as a dictionary and return\n",
        "    data = {\n",
        "        'X': X,\n",
        "        'Y': Y\n",
        "    }\n",
        "    return data\n",
        "\n",
        "print(\"genData is defined\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W61_98k2Jvw2"
      },
      "source": [
        "def displaySample(X,Ypred,Y,k,A,B):\n",
        "    # This function will display one sample of input and output data\n",
        "    # Inputs:\n",
        "    # ->     X = a [N,n,m,1] array of input image samples\n",
        "    # -> Ypred = a [N,n,m,1] array of output image samples\n",
        "    # ->     Y = a [N,n,m,1] array of truth image samples\n",
        "    # ->     k = the sample number to display\n",
        "\n",
        "\n",
        "    # Pick out the sample\n",
        "    x =     X[k,:,:,0].squeeze()\n",
        "    p = Ypred[k,:,:,0].squeeze()\n",
        "    y =     Y[k,:,:,0].squeeze()\n",
        "    \n",
        "    # Set up the figure and axes\n",
        "    fig, axs = plt.subplots(1,3,figsize=(15,5))\n",
        "\n",
        "    # Set the norm and colormap\n",
        "    norm0 = mpl.colors.Normalize(vmin=-3*B, vmax=3*B+A)\n",
        "    norm1 = mpl.colors.Normalize(vmin=0, vmax=1)\n",
        "    cmap='cool'\n",
        "\n",
        "    # Display the images\n",
        "    axs[0].imshow(x, norm=norm0, cmap=cmap)\n",
        "    axs[0].set_title('Input')\n",
        "    axs[0].axis('off')\n",
        "    fig.colorbar(plt.cm.ScalarMappable(norm=norm0, cmap=cmap), ax=axs[0], orientation='horizontal', shrink=0.75)\n",
        "    axs[1].imshow(p, norm=norm1, cmap=cmap)\n",
        "    axs[1].set_title('Output')\n",
        "    axs[1].axis('off')\n",
        "    fig.colorbar(plt.cm.ScalarMappable(norm=norm1, cmap=cmap), ax=axs[1], orientation='horizontal', shrink=0.75)\n",
        "    axs[2].imshow(y, norm=norm1, cmap=cmap)\n",
        "    axs[2].set_title('Truth')\n",
        "    axs[2].axis('off')\n",
        "    fig.colorbar(plt.cm.ScalarMappable(norm=norm1, cmap=cmap), ax=axs[2], orientation='horizontal', shrink=0.75)\n",
        "    \n",
        "print(\"displaySample is defined\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-lFIvWbAJzGr"
      },
      "source": [
        "def displayIntermediateOutput(model,layer,X,Y,k,A,B):\n",
        "    # This function will display output from a layer in the model for sample k \n",
        "    # from set X.\n",
        "    # Inputs:\n",
        "    # -> model = the model to take intermediate output from\n",
        "    # -> layer = the layer number to take output from\n",
        "    # ->     X = data size [N,n,m,1] array of input image samples\n",
        "    # ->     Y = data size [N,n,m,1] array of truth image samples\n",
        "    # ->     k = index of the data sample to be plotted\n",
        "\n",
        "    # Pick out the sample, keeping dimensions for input\n",
        "    x = X[k,:,:,:].reshape(1,X.shape[1],X.shape[2],1)\n",
        "    y = Y[k,:,:,0].squeeze()\n",
        "\n",
        "    # snip the model so the output is at the desired layer\n",
        "    model_snip = tf.keras.Model( inputs=model.input, outputs=model.layers[layer].output )\n",
        "\n",
        "    # Send the sample through both models\n",
        "    #ypred1 = model.predict(x).squeeze()  # This works but gives a warning so below is used instead. I don't get it\n",
        "    #ypred2 = model_snip.predict(x).squeeze()  # This works but gives a warning so below is used instead. I don't get it\n",
        "    ypred1 = np.array(model.predict_step(x)).squeeze()\n",
        "    ypred2 = np.array(model_snip.predict_step(x)).squeeze()\n",
        "    \n",
        "    # Reshape the intermediate output (align channels horizontally)\n",
        "    ypred2 = ypred2.reshape((ypred2.shape[0],-1))\n",
        "\n",
        "\n",
        "    # Set up the figure and axes\n",
        "    fig, axs = plt.subplots(1,3,figsize=(15,5))\n",
        "\n",
        "    # Set the norm and colormap\n",
        "    norm0 = mpl.colors.Normalize(vmin=-3*B, vmax=3*B+A)\n",
        "    norm1 = mpl.colors.Normalize(vmin=0, vmax=1)\n",
        "    cmap='cool'\n",
        "\n",
        "    # Display the images\n",
        "    axs[0].imshow(x.squeeze(), norm=norm0, cmap=cmap)\n",
        "    axs[0].set_title('Input')\n",
        "    axs[0].axis('off')\n",
        "    fig.colorbar(plt.cm.ScalarMappable(norm=norm0, cmap=cmap), ax=axs[0], orientation='horizontal', shrink=0.75)\n",
        "    axs[1].imshow(ypred2, norm=norm1, cmap=cmap)\n",
        "    axs[1].set_title('Intermediate Output')\n",
        "    axs[1].axis('off')\n",
        "    fig.colorbar(plt.cm.ScalarMappable(norm=norm1, cmap=cmap), ax=axs[1], orientation='horizontal', shrink=0.75)\n",
        "    axs[2].imshow(y, norm=norm1, cmap=cmap)\n",
        "    axs[2].set_title('Truth')\n",
        "    axs[2].axis('off')\n",
        "    fig.colorbar(plt.cm.ScalarMappable(norm=norm1, cmap=cmap), ax=axs[2], orientation='horizontal', shrink=0.75)\n",
        "\n",
        "print(\"displayIntermediateOutput is defined\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PMBl-XzPJ2Cf"
      },
      "source": [
        "def displayFilterChannel(model,layer,index1,index2):\n",
        "    # Display a filter from a convolutional layer\n",
        "    # Inputs:\n",
        "    # -> model  = the model to take intermediate output from\n",
        "    # -> layer  = the layer number to take output from\n",
        "    # -> index1 = the filter channel (what channel of the input)\n",
        "    # -> index2 = the filter index (which filter to look at)\n",
        "\n",
        "    # Get the weights from the layer\n",
        "    W = model.layers[layer].get_weights()[0]\n",
        "\n",
        "    # Get the specific filter channel\n",
        "    w = W[:,:,index1,index2].squeeze()\n",
        "\n",
        "    # Make a title\n",
        "    t = \"Kernel Values\"\n",
        "\n",
        "    # Display the image\n",
        "    plt.imshow(w)\n",
        "    plt.title(t)\n",
        "    plt.axis('off')\n",
        "    plt.colorbar()\n",
        "    plt.show()\n",
        "\n",
        "print(\"displayFilterChannel is defined\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cPhrD5CJ1CUR"
      },
      "source": [
        "# Simulate a Data Set"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UZZVSaM2MVaK"
      },
      "source": [
        "N = 500    # Number of samples\n",
        "n = 12     # Height\n",
        "m = 12     # Width\n",
        "p = 0.5    # Probability of a smiley\n",
        "A = 3      # Amplitude of smiley\n",
        "B = 1      # Standard deviation of normal noise\n",
        "data = genData(N,n,m,p,A,B)\n",
        "X = data['X']    # Input images\n",
        "Y = data['Y']    # Truth images\n",
        "\n",
        "# Display shapes and a sample\n",
        "print(\"The shape of X:\", data['X'].shape)\n",
        "print(\"The shape of Y:\", data['Y'].shape)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "830CvHZuADuc"
      },
      "source": [
        "for k in [0,1,2,3]:\n",
        "    displaySample(X,np.zeros(shape=X.shape),Y,k,A,B)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yNvtyWeaN6cE"
      },
      "source": [
        "# Split into training and testing\n",
        "train_size = 400\n",
        "Xtrain = X[           :train_size, :, :, : ]\n",
        "Xtest  = X[ train_size:          , :, :, : ]\n",
        "Ytrain = Y[           :train_size, :, :, : ]\n",
        "Ytest  = Y[ train_size:          , :, :, : ]\n",
        "\n",
        "# Display shapes\n",
        "print(\"The shape of Xtrain:\", Xtrain.shape)\n",
        "print(\"The shape of Xtest: \",  Xtest.shape)\n",
        "print(\"The shape of Ytrain:\", Ytrain.shape)\n",
        "print(\"The shape of Ytest: \",  Ytest.shape)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RdTniptd1Qb-"
      },
      "source": [
        "# Build a CNN Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CaBamMJfPatT"
      },
      "source": [
        "# Build a UNet\n",
        "X0 = tf.keras.Input( shape=( n,m,1 ) )\n",
        "\n",
        "# Convolution\n",
        "C1 = tf.keras.layers.Conv2D(\n",
        "    filters     = 1,\n",
        "    kernel_size = (5,5),\n",
        "    strides     = (1,1),\n",
        "    padding     = 'same',\n",
        "    activation  = 'relu'\n",
        ")(X0)\n",
        "\n",
        "# Pool\n",
        "P1 = tf.keras.layers.MaxPool2D(\n",
        "    pool_size    = (3,3)\n",
        ")(C1)\n",
        "\n",
        "# Convolution\n",
        "C2 = tf.keras.layers.Conv2D(\n",
        "    filters     = 1,\n",
        "    kernel_size = (5,5),\n",
        "    strides     = (1,1),\n",
        "    padding     = 'same',\n",
        "    activation  = 'relu'\n",
        ")(P1)\n",
        "\n",
        "# Upsample\n",
        "U1 = tf.keras.layers.Conv2DTranspose(\n",
        "    filters     = 1, \n",
        "    kernel_size = (3,3), \n",
        "    strides     = (3,3), \n",
        "    padding='same'\n",
        ")(C2)\n",
        "\n",
        "# Add\n",
        "A1 = tf.keras.layers.Concatenate()([U1, C1])\n",
        "\n",
        "# Convolution\n",
        "C3 = tf.keras.layers.Conv2D(\n",
        "    filters     = 1,\n",
        "    kernel_size = (5,5),\n",
        "    strides     = (1,1),\n",
        "    padding     = 'same',\n",
        "    activation  = 'relu'\n",
        ")(A1)\n",
        "\n",
        "model = tf.keras.Model(inputs=X0, outputs=C3)\n",
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z4ggJc1RA1j0"
      },
      "source": [
        "tf.keras.utils.plot_model( model, dpi=64 )"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nq2-BNrgBGmy"
      },
      "source": [
        "# Compile\n",
        "model.compile(\n",
        "    optimizer = tf.keras.optimizers.Adam(learning_rate=0.01),\n",
        "    loss      = 'mse'\n",
        ")\n",
        "print(\"Model Compiled\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WVkdQaNBQnaI"
      },
      "source": [
        "# Predict\n",
        "YtestPred = np.array(model.predict_step(Xtest))\n",
        "print(\"Untrained Predictions\")\n",
        "for k in [0,1,2,3]:\n",
        "    displaySample(Xtest,YtestPred,Ytest,k,A,B)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8D7aN8Gf1Z30"
      },
      "source": [
        "# Train the Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1OA_qFeuR7N-"
      },
      "source": [
        "hist = model.fit(\n",
        "    x = Xtrain,\n",
        "    y = Ytrain,\n",
        "    validation_data = (Xtest, Ytest),\n",
        "    batch_size = 5,\n",
        "    epochs = 100\n",
        ")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z-WoLOVI1dUo"
      },
      "source": [
        "# Evaluate the Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_IQuAcOHSSq3"
      },
      "source": [
        "# Predict\n",
        "YtestPred = np.array(model.predict_step(Xtest))\n",
        "print(\"Trained Predictions\")\n",
        "for k in [0,1,2,3,4,5,6]:\n",
        "    displaySample(Xtest,YtestPred,Ytest,k,A,B)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iqV7dc2MYhgG"
      },
      "source": [
        "# Display an image of the kernels\n",
        "l = 1\n",
        "ind1 = 0  # channel index\n",
        "ind2 = 0  # filter number\n",
        "for l in [1,3,4]:\n",
        "    displayFilterChannel(model,l,ind1,ind2)\n",
        "displayFilterChannel(model,6,ind1,ind2)\n",
        "displayFilterChannel(model,6,ind1+1,ind2)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xM571g5rGQSr"
      },
      "source": [
        "l = 6\n",
        "k = 2\n",
        "for l in [1,2,3,4,5,6]:\n",
        "    displayIntermediateOutput(model,l,Xtest,Ytest,k,A,B)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}